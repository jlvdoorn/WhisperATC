{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Whisper on ANSP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = 'ansp_data/audio'\n",
    "mdl = 'openai/whisper-large-v2'\n",
    "wsp = '-'.join(mdl.split('-')[1:])\n",
    "\n",
    "print('Dataset: ', dts)\n",
    "print('Model  : ', mdl)\n",
    "print('Whisper: ', wsp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = glob.glob(dts+'/*.wav')\n",
    "if len(wav_files) == 0:\n",
    "    raise Exception('No wav files found. Please check the path.')\n",
    "else:\n",
    "    print('Found {} audio files'.format(len(wav_files)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['hyp-prmpt', 'hyp-clean', 'ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model('-'.join(mdl.split('-')[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting inference...')\n",
    "time_start = datetime.time\n",
    "nato = \"alpha,bravo,charlie,delta,echo,foxtrot,golf,hotel,india,juliett,kilo,lima,mike,november,oscar,papa,quebec,romeo,sierra,tango,uniform,victor,whiskey,xray,yankee,zulu\"\n",
    "terminology = \"climb, climbing, descend, descending, passing, feet, knots, degrees, direct, maintain, identified, ILS, VFR, IFR, contact, frequency, turn, right, left, heading, altitude, flight, level, cleared, squawk, approach, runway, established, report, affirm, negative, wilco, roger, radio, radar, right, left, center\"\n",
    "sids = \"BERGI WISPA ANDIK BETUS NOPSU SPY TORGA ARNEM ELPAT NYKER EDUPO IVLUT RENDI LOPIK OGINA ROVEN KUDAD LARAS WOODY IDRID VOLLA\"\n",
    "\n",
    "for file in wav_files:\n",
    "    prompt = 'Air Traffic Control Communications ' + sids.replace(',',' ') + ' ' + nato.replace(',',' ') + ' ' + terminology.replace(',',' ')\n",
    "    \n",
    "    res_prmpt = model.transcribe(file, initial_prompt=prompt, language='en', fp16=False)\n",
    "    res_clean = model.transcribe(file, language='en', fp16=False)\n",
    "    df.loc[len(df.index)] = [res_prmpt['text'], res_clean['text'], ' ']\n",
    "    \n",
    "    i = wav_files.index(file)+1\n",
    "    print('Inference: {:.3f} %'.format(i/len(wav_files)*100), end='\\r')\n",
    "\n",
    "time_end = datetime.time\n",
    "print('Finished {} files in {:.2f} seconds'.format(len(wav_files), (time_end-time_start)/60))\n",
    "df.to_excel('ANSP-'+mdl.split('/')[-1]+'-'+datetime.today().strftime('%Y-%m-%d--%H:%M:%S')+'.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current = os.path.dirname(os.path.realpath(__file__))\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent+'/Evaluate')\n",
    "from Normalizer import filterAndNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ref-norm'] = df.apply(lambda x: filterAndNormalize(x['ref']), axis=1)\n",
    "df['hyp-clean-norm'] = df.apply(lambda x: filterAndNormalize(x['hyp-clean']), axis=1)\n",
    "df['hyp-prmpt-norm'] = df.apply(lambda x: filterAndNormalize(x['hyp-prmpt']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WER Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWER(df):\n",
    "    dff = df\n",
    "    wer_cln = jiwer.wer(list(dff['ref']), list(dff['hyp-clean']))\n",
    "    wer_prm = jiwer.wer(list(dff['ref']), list(dff['hyp-prmpt']))\n",
    "    wer_cln_nrm = jiwer.wer(list(dff['ref-norm']), list(dff['hyp-clean-norm']))\n",
    "    wer_prm_nrm = jiwer.wer(list(dff['ref-norm']), list(dff['hyp-prmpt-norm']))\n",
    "\n",
    "    print('clean        : {} %'.format(round(wer_cln*100,4)))\n",
    "    print('prmpt        : {} %'.format(round(wer_prm*100,4)))\n",
    "    print('clean-norm   : {} %'.format(round(wer_cln_nrm*100,4)))\n",
    "    print('prmpt-norm   : {} %'.format(round(wer_prm_nrm*100,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = '-'.join(mdl.split('-')[1:])\n",
    "\n",
    "print('Dataset: ', dts)\n",
    "print('Model  : ', mdl)\n",
    "print('Whisper: ', wsp)\n",
    "\n",
    "calcWER(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
